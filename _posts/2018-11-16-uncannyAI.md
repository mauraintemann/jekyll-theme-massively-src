---
layout: post
title:  "UNCANNY A.I."
date:   2018-11-16
excerpt: ""
image: "/images/"
---

In “The Lifecycle of Software Objects,” Ted Chiang imagines a future where “digients,” animal-like A.I. that learn and emote, accompany humans in virtual worlds of our creation. The desire for such technology does not seem so unfounded; the digients are almost reminiscent of overgrown, talking Tamagotchi. But while Tamagotchi are comprised of a couple dozen 2D pixels, Chiang’s digients are 3D, operating on the same virtual plane as the 3D avatars of the humans within the virtual world, even allowed to occasionally inhabit real-world robotic bodies. In the story, software designer Derek discusses creating the aesthetics of these A.I., trying to find a balance within the uncanny valley of cute and off-putting. 

> “To get customers to put in that kind of effort, everything about the digients has to be appealing: their personalities need to be charming, which the developers are working on, and their avatars need to be cute, which is where Derek comes in. But he can’t simply give the digients enormous eyes and short noses. If they look like cartoons, no on will take them seriously. Conversely, if they look too much like real animals, their facial expressions and ability to speak becomes disconcerting.” (7)

This balance is a real concern of today’s A.I. developers. In Clive Thompson’s piece  <a href="https://www.nytimes.com/interactive/2018/11/14/magazine/tech-design-ai-chatbot.html?rref=collection%2Fsectioncollection%2Fmagazine&action=click&contentCollection=magazine&region=rank&module=package&version=highlights&contentPlacement=7&pgtype=sectionfront">“May A.I. Help You?”</a>, he writes about A.I. in our post-Turing world, where bots are self-aware of their non-humanity. He claims that botmakers are more often developing bots that don’t pretend to be human, because “they’ve realized that the public tends to feel wounded when someone (or something) tries to fool them.” Beyond this, we’ve also been conditioned by many a Sci-Fi movie and dystopian novel to feel uncomfortable, even threatened by A.I. that is indistinguishable from a human. We are quicker to imagine hyper-real A.I. taking over the world rather than an online chatbot or Siri, A.I. that don't pretend to be human, but instead “[lean] into the artifice,” as Thompson writes. In Chiang’s story, as well as in our own world, we willingly accept these post-Turing A.I. into our digital spaces, our homes, and our lives. But the essence of these bots are the same, even if their “personalities” are different. If hyper-real A.I. feels threatening, should we not feel even more threatened by A.I. that we actively *allow* to infiltrate every aspect of our lives? Do we make A.I. *more* threatening when we package them as friendly and self-aware? In our ironic rejection of human-like bots, we reveal a fundamental human discomfort in this age of A.I. -- if our humanity can be distilled, recreated, and sold, what will we reserve to differentiate *us* and *them*?
